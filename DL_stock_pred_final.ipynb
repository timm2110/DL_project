{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Stock Prediction \n","In diesem Notebook soll mit verschiedenen Deep Learning Methoden der Kurs einer Aktie vorhergesagt werden. <br>\n","<ins>Ziele</ins> : <br>\n","- Implementierung von LSTM Algorithmus zur Vorhersage von einem Tag mit den vorherigen 100 Tagen als Input\n","- Implementierung von LSTM Algorithmus zur Vorhersage von 4 Tagen mit den vorherigen 100 Tagen als Input\n","- Vorhersage von einem Tag mithilfe von Linearer Regression\n","- Vorhersage von 1 Tag mithilfe von 1D Convolution\n","- Einfache Vorhersage mit einer Baseline indem der naechste Tag den Wert des vorherigen tages annimmt\n","- Vergleich der Performance all dieser Algorithmen in Bezug auf Accuracy und Anwendbarkeit\n","- bestehen des DL Moduls\n"]},{"cell_type":"markdown","metadata":{},"source":["## Laden der notwendigen Libraries\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import os\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n","\n","import os\n","import datetime\n","\n","\n","\n","# load required libraries:\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from tensorflow.keras.layers import LSTM, Dense, Convolution2D, MaxPooling2D, Flatten , Activation, Lambda, Convolution1D\n","from tensorflow.keras.utils import to_categorical \n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False\n","\n","import matplotlib.pyplot as plt\n","#%matplotlib qt\n","plt.style.use('default')\n","\n","path = './kaggle/Input/Stocks/'\n","path='archive/Data/Stocks/'\n","#path='Stocks/' #gesch√§ftlich\n","stocks = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Individuelles auswaehlen verschiedner Aktien, nach Bedarf des Bedieners.<br>\n","Als Hinweis: <br>\n","- Tesla - tsla\n","- Microsoft - msft\n","- Apple - AAPl"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["while True:\n","    stock = input('Pick a stock:')\n","    stock += '.us.txt'\n","    if stock in stocks:\n","        print('Found stock')\n","        data = pd.read_csv(path + stock)\n","        df = pd.read_csv(path + stock)\n","        break\n","    else:\n","        print('Stock not found')\n","        continue\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.head()\n","#np.shape(data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.describe()\n","type(data)\n","dataTypeSeries = data.dtypes\n","print('Data type of each column of Dataframe :')\n","print(dataTypeSeries)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.drop('OpenInt', axis=1, inplace=True)\n","df.drop('OpenInt', axis=1, inplace=True)\n","#df = data.tail(260)\n","#df = data\n","print(data, df)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Anzeige der Aktie "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.express as px\n","import plotly.graph_objects as go\n","\n","fig = go.Figure(data=[go.Candlestick(x=data.Date, \n","                                     open=data.Open, \n","                                     high=data.High, \n","                                     low=data.Low, \n","                                     close=data.Close)])\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Funktionen\n","Nachfolgende ist die Implementierung verschiedener Funktionen. "]},{"cell_type":"markdown","metadata":{},"source":["Liste aller files im Ordner"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def files_list(data_path):\n","    files=[]\n","    for file in os.listdir(data_path):\n","        if file.endswith('.txt'):\n","            \n","            files.append(os.path.join(data_path, file))\n","    return files\n"]},{"cell_type":"markdown","metadata":{},"source":["Einlesen der Dateien."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def txt_to_df(path):\n","    df=pd.read_csv(path,sep=',')\n","    df['Date']=pd.to_datetime(df.Date,format='%Y-%m-%d')\n","    df=df[['Date','Close']]\n","    scaler=MinMaxScaler(feature_range=(0,1))\n","    df['Close']=scaler.fit_transform(np.array(df.Close).reshape(-1,1))\n","    return df,scaler\n"]},{"cell_type":"markdown","metadata":{},"source":["Spalten und Transformieren der Datensets in fuer den Algorithmus angepasste Form."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_dataset(dataset, time_step=1):\n","    print(time_step)\n","    dataX, dataY = [], []\n","    for i in range(len(dataset)-time_step-1):\n","        a = dataset.Close[i:(i+time_step)]\n","        dataX.append(a)\n","        dataY.append(dataset.Close[i + time_step])\n","    return np.array(dataX), np.array(dataY)\n","\n","def create_dataset_10(dataset, time_step=1):\n","    dataX, dataY = [], []\n","    for i in range(len(dataset)-time_step-4):\n","        a = dataset.Close[i:i+time_step]\n","        dataX.append(a)\n","        \n","        b=dataset.Close[i+time_step:i+time_step+4]\n","        dataY.append(b)\n","        \n","    return np.array(dataX), np.array(dataY)\n"]},{"cell_type":"markdown","metadata":{},"source":["Nachfolgend werden die Funktionen aufgerufen und die jeweiligen Daten eingelesen.<br>\n","<ins>Wichtig:</ins> der Dateipfad muss an das jeweilige Verzeichnis angepasst werden. <br>\n","<br>\n","Als Spaltung der test und Trainingsdaten wurde das Jahr 2016 verwendet. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","#data_path='archive/Data/Stocks/'\n","data_path='kaggle/Input/Stocks/'\n","data_path='archive/Data/Stocks/'\n","#data_path='Stocks/'\n","file_list=files_list(data_path)\n","\n","ind=[i for i, s in enumerate(file_list) if 'tsla' in s]\n","\n","data,scaler=txt_to_df(data_path+'tsla.us.txt')\n","\n","# =============================================================================\n","# test=data.loc[data.Date=='2015-04-01'].index[0]\n","# data=data[test:]\n","# data.reset_index(inplace=True)\n","# =============================================================================\n","\n","cut_off=data.loc[data.Date=='2016-03-01'].index[0]\n","\n","train_data=data[:cut_off]\n","test_data=data[cut_off:]\n","test_data.reset_index(inplace=True)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Um 1 Tag vorherzusagen, werden die letzten 100 Tage vo diesem Tag als Input fuer den Algorithmus genommen. <br>\n","Man koennte auch weniger Time Steps als Input nehmen. Auch bei der 4 Tages vorhersage wurden die letzten 100 <br>\n","Tage als Input ausgesucht, um eine gewisse Vergleichbarkeit mit der Ein-Tages-Vorhersage gewaehrleisten zu koennen."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","time_step = 100\n","X_train, y_train = create_dataset(train_data, time_step)\n","X_test, y_test = create_dataset(test_data, time_step)\n","\n","X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n","X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n","#X_train\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","time_step = 100\n","X_train_10, y_train_10 = create_dataset_10(train_data, time_step)\n","X_test_10, y_test_10 = create_dataset_10(test_data, time_step)\n","\n","X_train_10 = X_train_10.reshape(X_train_10.shape[0],X_train_10.shape[1] , 1)\n","X_test_10 = X_test_10.reshape(X_test_10.shape[0],X_test_10.shape[1] , 1)\n","#X_train\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Implementierung der 4 Tage Vorhersage mit LSTM- Algorithmus\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_lstm_10=Sequential()\n","model_lstm_10.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n","#model.add(Dropout=0.2)\n","model_lstm_10.add(LSTM(50,return_sequences=True))\n","model_lstm_10.add(LSTM(50))\n","model_lstm_10.add(Dense(4))\n","model_lstm_10.compile(loss='mean_squared_error',optimizer='adam')\n","\n","\n","#model_lstm_10.fit(X_train_10,y_train_10,epochs=100,batch_size=32)\n","\n","if os.path.exists('./StockModel_LSTM_10_02.h5'):\n","    print(\"Loading model\")\n","    model_lstm_10 = tf.keras.models.load_model('./StockModel_LSTM_10_02.h5')\n","else:\n","    history=model_lstm_10.fit(X_train_10, y_train_10, \n","                      epochs=100, \n","                      batch_size=32, \n","                      verbose=1)\n","    model_lstm_10.save('./StockModel_LSTM_10_02.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","train_pred=[]\n","for i in range(0,len(X_train_10),1):\n","    data=X_train_10[i]\n","    data=data.reshape((1, len(data), 1))\n","    lstm_train_predict=model_lstm_10.predict(data)\n","    train_pred.append(lstm_train_predict)\n","\n","test_pred=[]\n","for i in range(0,len(X_test_10),1):\n","    data=X_test_10[i]\n","    data=data.reshape((1, len(data), 1))\n","    lstm_test_predict=model_lstm_10.predict(data)\n","    test_pred.append(lstm_test_predict)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_pred=np.array(test_pred)\n","train_pred=np.array(train_pred)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Vergleich der 4-Tage Vorhersage zum eigentlichen Aktienkurs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig,ax=plt.subplots()\n","ax.plot(test_pred.flatten(),color='red',label='Test data pred')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","ax.plot(y_test_10.flatten(),color='blue', label= 'Test data')\n","plt.legend(loc=\"upper left\")\n","\n","fig1,ax=plt.subplots()\n","ax.plot(train_pred.flatten(),color='red',label='Train data prediction')\n","ax.plot(y_train_10.flatten(),color='blue', label= 'Training data')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","plt.legend(loc=\"upper left\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Implementierung 1-Tag Vorhersage mit LSTM- Algorithmus"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model=Sequential()\n","model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n","model.add(LSTM(50,return_sequences=True))\n","model.add(LSTM(50))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error',optimizer='adam')\n","\n","\n","#model.fit(X_train,y_train,epochs=10,batch_size=32)\n","\n","\n","if os.path.exists('./StockModel_LSTM_02.h5'):\n","    print(\"Loading model\")\n","    model = tf.keras.models.load_model('./StockModel_LSTM_02.h5')\n","else:\n","    history=model.fit(X_train, y_train, \n","                      epochs=100, \n","                      batch_size=32, \n","                      verbose=1)\n","    model.save('./StockModel_LSTM_02.h5')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Vergleich der 1 -Tag Vorhersage zum eigentlichen Aktienkus"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lstm_train_predict=model.predict(X_train)\n","lstm_test_predict=model.predict(X_test)\n","\n","fig,ax=plt.subplots()\n","ax.plot(lstm_test_predict,color='red',label='Test data pred')\n","ax.plot(y_test,color='blue', label= 'Test data')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","plt.legend(loc=\"upper left\")\n","\n","fig1,ax=plt.subplots()\n","ax.plot(lstm_train_predict,color='red',label='Train data prediction')\n","ax.plot(y_train,color='blue', label= 'Training data')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","plt.legend(loc=\"upper left\")\n","# =============================================================================\n","# y_train=scaler.inverse_transform(np.array(y_train).reshape(-1,1))\n","# =============================================================================\n","\n","# =============================================================================\n","# train_predict=scaler.inverse_transform(train_predict)\n","# test_predict=scaler.inverse_transform(test_predict)\n","# =============================================================================\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Accuracy\n","Laueft nur problemlos durch, wenn der Algorithmus neu gebildet wird und nicht geladen."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(history.history.keys())\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['accuracy'], color = 'red')\n","#plt.plot(history.history['val_loss'])\n","\n","plt.xlabel('Epoch')\n","plt.ylabel('Mean Absolute Error Loss')\n","plt.title('Loss Over Time')\n","plt.legend(['Train','Accuracy'])\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### 1.te Versuch der 1D Convolution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# =============================================================================\n","# import tensorflow as tf\n","# from keras.layers import Flatten\n","# from keras.layers.convolutional import Conv1D\n","# from keras.layers.convolutional import MaxPooling1D\n","# \n","# model_1Dconv = Sequential()\n","# ks = 3\n","# model_1Dconv.add(Convolution1D(filters=32, activation=\"relu\", kernel_size=ks, padding='causal', input_shape=(100, 1)))\n","# #model_1Dconv.add(Convolution1D(filters=32, activation=\"relu\", kernel_size=ks, padding='causal'))\n","# #model_1Dconv.add(Convolution1D(filters=32, activation=\"relu\", kernel_size=ks, padding='causal'))\n","# model_1Dconv.add(Convolution1D(filters=32, activation=\"relu\", kernel_size=ks, padding='causal'))\n","# model_1Dconv.add(MaxPooling1D(pool_size=2))\n","# model_1Dconv.add(Flatten())\n","# #model_1Dconv.add(Dense(32))\n","# model_1Dconv.add(Dense(1))\n","# \n","# \n","# model_1Dconv.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n","# model_1Dconv.summary()\n","# =============================================================================\n","\n","# =============================================================================\n","# history = model_1Dconv.fit(X_train, y_train,\n","#                     epochs=100,\n","#                     batch_size=32)\n","# =============================================================================\n","\n","\n","# =============================================================================\n","# print(history.history.keys())\n","# plt.plot(history.history['loss'])\n","# plt.plot(history.history['accuracy'], color = 'red')\n","# #plt.plot(history.history['val_loss'])\n","# \n","# plt.xlabel('Epoch')\n","# plt.ylabel('Mean Absolute Error Loss')\n","# plt.title('Loss Over Time')\n","# plt.legend(['Train','Accuracy'])\n","# =============================================================================\n","\n","\n","# Prediction 1D CNN\n","# =============================================================================\n","# train_predict=model_1Dconv.predict(X_train)\n","# test_predict=model_1Dconv.predict(X_test)\n","# \n","# fig,ax=plt.subplots()\n","# ax.plot(test_predict,color='red',label='Test data pred')\n","# ax.plot(y_test,color='blue', label= 'Test data')\n","# ax.set_ylabel('norm. USD $')\n","# ax.set_xlabel('samples')\n","# plt.legend(loc=\"upper left\")\n","# \n","# fig1,ax=plt.subplots()\n","# ax.plot(train_predict,color='red',label='Train data prediction')\n","# ax.plot(y_train,color='blue', label= 'Training data')\n","# ax.set_ylabel('norm. USD $')\n","# ax.set_xlabel('samples')\n","# plt.legend(loc=\"upper left\")\n","# =============================================================================\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Implementierung der 1-Tag Vorhersage mit 1D- Convolution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from numpy import array\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","\n","#1 D Conv Prediction \n","conv_1d_model = Sequential()\n","conv_1d_model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(100, 1)))\n","conv_1d_model.add(MaxPooling1D(pool_size=2))\n","conv_1d_model.add(Flatten())\n","conv_1d_model.add(Dense(50, activation='relu'))\n","conv_1d_model.add(Dense(1))\n","conv_1d_model.compile(optimizer='adam', loss='mse')\n","\n","if os.path.exists('./StockModel_1CNN_02.h5'):\n","    print(\"Loading model\")\n","    conv_1d_model= tf.keras.models.load_model('./StockModel_1CNN_02.h5')\n","else:\n","    history=conv_1d_model.fit(X_train, y_train, \n","                      epochs=50, \n","                      batch_size=32, \n","                      verbose=1)\n","    conv_1d_model.save('./StockModel_1CNN_02.h5')\n","\n","\n","train_predict=conv_1d_model.predict(X_train)\n","test_predict=conv_1d_model.predict(X_test)\n","\n","fig,ax=plt.subplots()\n","ax.plot(test_predict,color='red',label='Test data pred')\n","ax.plot(y_test,color='blue', label= 'Test data')\n","plt.legend(loc=\"upper left\")\n","\n","fig1,ax=plt.subplots()\n","ax.plot(train_predict,color='red',label='Train data prediction')\n","ax.plot(y_train,color='blue', label= 'Training data')\n","plt.legend(loc=\"upper left\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Impelementierung der 1-Tag Vorhersage durch Lineare Regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from tensorflow import keras\n","from tensorflow.keras import layers\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["time_step = 100\n","X_train, y_train = create_dataset(train_data, time_step)\n","X_test, y_test = create_dataset(test_data, time_step)\n","\n","X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n","X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n","#X_train\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#built the neural network architecture\n","model_lin= Sequential()\n","model_lin.add(Dense(15, input_dim=100, activation='relu'))\n","#model_lin.add(Dense(7, activation='relu'))\n","#model_lin.add(Dense(3, activation='relu'))\n","model_lin.add(Dense(1, activation='linear'))\n","model_lin.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_lin.compile(optimizer='adam', loss='mse')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#train the neural network on the train dataset\n","history= model_lin.fit(X_train, y_train, epochs=50, validation_split=0.2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#plot the loss and validation loss of the dataset\n","history_lin = pd.DataFrame(history.history)\n","plt.plot(history_lin['loss'], label='loss')\n","plt.plot(history_lin['val_loss'], label='val_loss')\n","\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#evaluate the model\n","model_lin.evaluate(X_test, y_test, batch_size=128)\n"]},{"cell_type":"markdown","metadata":{},"source":["Vergleich der 1D- Convolution Vorhersage mit dem eigentlichen Aktienkurs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model_lin.predict(X_test)\n","\n","a = plt.axes(aspect='equal')\n","plt.scatter(y_test, y_pred, color = 'red')\n","plt.xlabel('Input')\n","plt.ylabel('Predicted values')\n","plt.title('True and predicted values')\n","plt.plot([0.5, 1], [0.5, 1])\n","\n","train_predict= model_lin.predict(X_train)\n","test_predict=model_lin.predict(X_test)\n","\n","fig,ax=plt.subplots()\n","ax.plot(test_predict,color='red',label='Test data pred')\n","ax.plot(y_test,color='blue', label= 'Test data')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","plt.legend(loc=\"upper left\")\n","\n","fig1,ax=plt.subplots()\n","ax.plot(train_predict,color='red',label='Train data prediction')\n","ax.plot(y_train,color='blue', label= 'Training data')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","plt.legend(loc=\"upper left\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Implementierung der Baseline\n","Als Vorhersage wird immer der Wert des Vortages genommen."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#als prediction einfach immer den Wert vom Vortag nehmen\n","from scipy.ndimage.interpolation import shift\n","base_train_predict=shift(y_train,1,cval=y_train[0])\n","base_test_predict=shift(y_test,1,cval=y_train[0])\n","\n","base_test_predict[0]=base_train_predict[-1]\n","\n","\n","fig,ax=plt.subplots()\n","ax.plot(base_test_predict,color='red',label='Test data pred')\n","ax.plot(y_test,color='blue', label= 'Test data')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","plt.legend(loc=\"upper left\")\n","\n","fig1,ax=plt.subplots()\n","ax.plot(base_train_predict,color='red',label='Train data prediction')\n","ax.plot(y_train,color='blue', label= 'Training data')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","plt.legend(loc=\"upper left\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_fehl_b=abs((y_test-base_test_predict))\n","y_fehl_lstm=abs((y_test-lstm_test_predict.flatten()))\n","\n","fig1,ax=plt.subplots()\n","ax.plot(y_fehl_b,color='red',label='Differenz base zu original')\n","ax.plot(y_fehl_lstm,color='blue', label= 'Differenz lstm zu original')\n","ax.set_ylabel('norm. USD $')\n","ax.set_xlabel('samples')\n","plt.legend(loc=\"upper left\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Kalkulation der Performance der verschiedenen Modelle und deren Vergleich"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Model Performance Calculation\n","model_performance = {}\n","# Performance measure Linear model Baseline\n","model_performance['Lin Reg'] = model_lin.evaluate(X_test, y_test, verbose=0)\n","# Performance measure 1D CNN\n","model_performance['1D CNN'] = conv_1d_model.evaluate(X_test, y_test, verbose=0)\n","# Performance measure LSTM\n","model_performance['LSTM'] = model.evaluate(X_test, y_test, verbose=0)\n","#\n","model_performance['LSTM_4'] = model.evaluate(X_test_10, y_test_10, verbose=0)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating model performance plot\n","models = list(model_performance.keys())\n","values = list(model_performance.values())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize = (5, 3))\n"," \n","# creating the bar plot\n","plt.bar(models, values, color ='blue',\n","        width = 0.1)\n"," \n","plt.xlabel(\"Modelle\")\n","plt.ylabel(\"Mean Square Error\")\n","plt.title(\"Modellvergleich\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Verbesserungsmoeglichkeiten\n","- Lstm mit Multi Step Prediction durch Encoder-Decoder System \n","- Trainieren der Daten mit mehr als nue einem Feature. Hier wurde nur der Closing Wert der Aktie am Tag verwendet. Es haetten auch weitere Features, wie Open-Wert verwendet werden koennen.\n","- Weniger oder mehr Tage als Input fuer die Vorhersage verwenden\n","- Test und Trainingsdaten Aufspaltung "]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
